# **実験レポート生成エンジン "Re-Lab" 実装設計書 v3.0 (完全版)**

## **1\. システム概要**

本システムは、PDF形式の実験指導書を入力とし、**Difyワークフローが出力するJSON構造と完全に同等（互換）のJSONデータ**を、Pythonの非同期処理を用いて高速に生成する。

### **コアコンセプト**

1. **完全なスキーマ再現**: Dify特有のネスト構造（output.result\_json や consideration オブジェクトなど）をPydanticモデルで厳密に定義し再現する。  
2. **ハイブリッド処理**:  
   * **LLM (Parallel)**: 「意味の解釈」（実験項目の抽出、考察の正規化、要約）を担当。  
   * **Python (Deterministic)**: 「構造の決定」（図表番号の採番、定型文の生成、JSONの組み立て）を担当。  
3. **PDF特化**: 提供された「電気工学実験」のフォーマット（2段組みの可能性、章番号「4.」「6.」など）に最適化する。

---

## **2\. データ構造設計 (Pydantic Schema)**

Difyの出力JSONを100%再現するためのクラス定義です。

Python

from typing import List, Optional, Literal, Any  
from pydantic import BaseModel, Field

\# \--- A. 基本部品 (Leaf Nodes) \---

class TableItem(BaseModel):  
    label: str \= Field(..., description="例: 表5.1")  
    caption: str

class FigureItem(BaseModel):  
    label: str \= Field(..., description="例: 図5.1")  
    caption: str

class ReferenceItem(BaseModel):  
    id: int  
    year: int  
    notes: str  
    title: str  
    authors: str  
    publisher: str

class UnitItem(BaseModel):  
    """考察の1単位"""  
    index: int  
    formulas\_used: List\[str\] \= Field(default\_factory=list)  
    reference\_ids: List\[int\]  
    formula\_numbers: List\[str\] \= Field(default\_factory=list)  
    discussion\_active: str  
    missing\_formula\_numbers: List\[str\] \= Field(default\_factory=list)

class ExperimentItem(BaseModel):  
    """実験項目（詳細情報含む）"""  
    idx: int  
    name: str  
    subidx: Optional\[int\] \= None  
    tables: List\[TableItem\]  
    figures: List\[FigureItem\]  
    description\_brief: str

\# \--- B. 中間構造 (Composite Nodes) \---

class ConsiderationGroup(BaseModel):  
    """JSON内の 'consideration' フィールド用"""  
    units: List\[UnitItem\]  
    references: List\[ReferenceItem\]  
    reference\_list\_formatted: List\[str\]

\# \--- C. コアデータ (Core Data Structure) \---

class ResultJson(BaseModel):  
    """  
    最も重要なデータ本体。  
    Difyの 'result\_json' キーに対応。  
    """  
    units: List\[UnitItem\]  
    chapter: int \= 5  
    summary: str  
    references: List\[ReferenceItem\]  
    experiments: List\[ExperimentItem\]  
    total\_count: int  
    consideration: ConsiderationGroup  
    reference\_list\_formatted: List\[str\]

\# \--- D. ラッパー (Wrappers for Dify Compatibility) \---

class OutputWrapper(BaseModel):  
    result\_json: ResultJson

class RootResponse(BaseModel):  
    """  
    最終出力JSONのルート定義。  
    Difyの仕様により、同じデータが複数の場所に重複して格納される構造を再現。  
    """  
    units: List\[UnitItem\]  
    output: OutputWrapper  
    chapter: int \= 5  
    outputs: OutputWrapper  
    summary: str  
    references: List\[ReferenceItem\]  
    experiments: List\[ExperimentItem\]  
    result\_json: ResultJson  
    total\_count: int  
    consideration: ConsiderationGroup  
    reference\_list\_formatted: List\[str\]

---

## **3\. 実装手順書 (Step-by-Step Implementation)**

### **Phase 1: 高速テキスト抽出と領域分割**

PDFライブラリ PyMuPDF (fitz) を使用し、テキストを抽出した上で、正規表現を用いて処理対象を厳密に切り分ける。

* **入力**: 実験指導書\_バイポーラトランジスタ...pdf  
* **ロジック**:  
  1. 全ページをテキスト化（ヘッダー・フッターのページ番号はY座標で除外）。  
  2. **正規表現スプリッター**:  
     * Method\_Text: r'^4\\.\\s\*実験方法' から始まり、r'^5\\.' または r'^6\\.' の前まで。  
     * Discussion\_Task\_Text: r'^6\\.\\s\*考察' から始まり、r'^7\\.' または 参考文献 の前まで。  
     * Summary\_Source: 文書全体（ただし目次や参考文献を除く）。

### **Phase 2: 非同期LLM処理 (Async Processing)**

3つの独立したタスクを asyncio.gather で並列実行する。これにより、直列処理に比べ **60%以上の時間短縮** を実現する。

#### **Task A: 実験構造の抽出 (Structure Extraction)**

* **入力**: Method\_Text  
* **プロンプト**: 「実験項目の『階層（章番号）』、『名称』、『実験タイプ（測定/計算/分析）』、『条件（IB=20μAなど）』のみを抽出せよ。図表番号やDescriptionは生成するな。」  
* **出力型**: 簡易JSON（リスト構造のみ）。

#### **Task B: 考察課題の正規化 (Discussion Normalization)**

* **入力**: Discussion\_Task\_Text  
* **プロンプト**: 「課題（6.1, 6.2...）ごとに分割し、文中の『考察せよ』等の命令形を『考察する』等の常体・能動態に書き換えよ。」  
* **出力型**: List\[UnitItem\] の原型。

#### **Task C: 全体要約 (Summary Generation)**

* **入力**: 全文テキスト  
* **プロンプト**: 「300字程度、だ・である調、過去形。目的・理論・手順・結論を簡潔に。」

### **Phase 3: 決定論的ロジックによる構築 (Deterministic Logic)**

LLMの出力（Raw Data）を受け取り、Pythonコードで最終的な値を確定させる。**ここが精度の肝となる。**

#### **1\. 図表番号の採番 (Auto Numbering)**

* table\_counter \= 1, fig\_counter \= 1 を初期化。  
* 実験リストをループし、実験タイプに応じて番号を割り振る。  
  * **測定**: tables (Data) と figures (Graph) を追加。  
  * **分析**: tables (Result) と figures (Graph) を追加。  
* **Caption生成**: f"{実験名称}測定データ" のように名称を結合。

#### **2\. Description Briefのテンプレート生成 (Template Injection)**

Difyのプロンプトで指示していた内容を、Pythonのf-stringで実装する。

* 例（測定）:  
  Python  
  desc \= f"{name}において、{condition}の各条件に対する特性を測定した結果を{table\_label}および{fig\_label}に示す。"

  これにより、LLMの気まぐれによる「てにをは」の揺れを排除し、常に完璧なフォーマットを出力する。

#### **3\. 参考文献リストの整形**

* ReferenceItem オブジェクトのリストから、"\[1\] 著者名 タイトル..." 形式の文字列リストを生成する。

### **Phase 4: 最終JSONの組み立て (Assembly)**

* Phase 3 で作成したデータを、Phase 1 の RootResponse スキーマに流し込む。  
* units や experiments などのデータを、ルートレベル、output 内、result\_json 内のそれぞれにコピーして配置する（Dify互換性のため）。

---

## **4\. 開発用コードスニペット (Core Logic)**

このコードは、最も複雑な「データの組み立て」部分の実装例です。

Python

import asyncio  
\# Pydanticモデル定義は上記を参照

class LabReportBuilder:  
    def \_\_init\_\_(self, chapter: int \= 5):  
        self.chapter \= chapter

    def build\_experiments(self, raw\_experiments: list) \-\> list\[ExperimentItem\]:  
        """LLMの抽出結果から、図表番号と説明文を生成して構造化する"""  
        results \= \[\]  
        t\_cnt \= 1  
        f\_cnt \= 1

        for exp in raw\_experiments:  
            \# 必須フィールドの取得  
            name \= exp.get("name", "")  
            cond \= exp.get("condition", "") \# LLMには "condition" として抽出させる  
            e\_type \= exp.get("type", "測定")  
              
            tables \= \[\]  
            figures \= \[\]  
              
            \# 実験タイプごとのロジック  
            if e\_type \== "測定":  
                \# 表と図の両方  
                t\_lbl \= f"表{self.chapter}.{t\_cnt}"  
                f\_lbl \= f"図{self.chapter}.{f\_cnt}"  
                  
                tables.append(TableItem(label=t\_lbl, caption=f"{name}測定データ"))  
                figures.append(FigureItem(label=f\_lbl, caption=name))  
                  
                \# テンプレート適用  
                desc \= f"{name}において、{cond}の条件で測定した結果を{t\_lbl}および{f\_lbl}に示す。"  
                  
                t\_cnt \+= 1  
                f\_cnt \+= 1

            elif e\_type \== "分析":  
                \# 結果表と図  
                t\_lbl \= f"表{self.chapter}.{t\_cnt}"  
                f\_lbl \= f"図{self.chapter}.{f\_cnt}"  
                  
                tables.append(TableItem(label=t\_lbl, caption=f"{name}"))  
                figures.append(FigureItem(label=f\_lbl, caption=f"{name}"))  
                  
                desc \= f"{name}の結果を整理して表を作成し、求めた結果を{t\_lbl}および{f\_lbl}に示す。"  
                  
                t\_cnt \+= 1  
                f\_cnt \+= 1  
              
            else: \# 計算など  
                f\_lbl \= f"図{self.chapter}.{f\_cnt}"  
                figures.append(FigureItem(label=f\_lbl, caption=f"計算上の{name}"))  
                desc \= f"{name}を計算した結果を{f\_lbl}に示す。"  
                f\_cnt \+= 1

            \# ExperimentItemの作成  
            item \= ExperimentItem(  
                idx=exp.get("idx"),  
                subidx=exp.get("subidx"),  
                name=name,  
                tables=tables,  
                figures=figures,  
                description\_brief=desc  
            )  
            results.append(item)  
              
        return results

    def assemble\_final\_json(self, summary: str, units: list, experiments: list, refs: list) \-\> str:  
        """全パーツを結合してDify互換JSONを出力"""  
          
        \# 1\. 参考文献の整形  
        ref\_formatted \= \[  
            f"\[{r.id}\]{r.authors} {r.title} {r.publisher} {r.year}"   
            for r in refs  
        \]  
          
        \# 2\. Considerationグループ作成  
        consideration \= ConsiderationGroup(  
            units=units,  
            references=refs,  
            reference\_list\_formatted=ref\_formatted  
        )

        \# 3\. Core Data作成  
        core \= ResultJson(  
            units=units,  
            chapter=self.chapter,  
            summary=summary,  
            references=refs,  
            experiments=experiments,  
            total\_count=len(units),  
            consideration=consideration,  
            reference\_list\_formatted=ref\_formatted  
        )

        \# 4\. Root Wrapper作成 (完全再現)  
        root \= RootResponse(  
            units=units,  
            output=OutputWrapper(result\_json=core),  
            chapter=self.chapter,  
            outputs=OutputWrapper(result\_json=core),  
            summary=summary,  
            references=refs,  
            experiments=experiments,  
            result\_json=core,  
            total\_count=len(units),  
            consideration=consideration,  
            reference\_list\_formatted=ref\_formatted  
        )

        return root.model\_dump\_json(indent=2)

## **5\. 次のアクション**

この設計により、入力されたPDFがどのようであっても、**構造的に崩れることがないJSON**が生成されます。

1. 上記Pythonコード（Pydantic定義とロジッククラス）を実装環境（ローカルPythonやCloud Functionsなど）にコピーしてください。  
2. Phase 2 のLLM呼び出し部分に、OpenAI APIキーを設定してください。  
3. PDFパーサー（Phase 1）を結合すれば、システムは完成です。