# 

## **1\. システムアーキテクチャ概要**

本システムは、PDFを入力とし、構造化されたJSONを出力するステートレスなバッチ処理パイプラインである。  
最大の特徴は\*\*「徹底的な非同期並列処理（Async I/O）」と「LLMとロジックの厳格な役割分担」\*\*にある。

### **処理フロー図**

コード スニペット

graph LR  
    Input\[PDFファイル\] \--\> A\[Text Extractor\]  
    A \--\> B\[Smart Splitter \<br/\> (Regex Logic)\]  
      
    subgraph Parallel Execution \[非同期並列実行ゾーン\]  
        B \--\> C1\[Task: Summary Gen \<br/\> (LLM)\]  
        B \--\> C2\[Task: Structure Extract \<br/\> (LLM)\]  
        B \--\> C3\[Task: Discussion Norm \<br/\> (LLM)\]  
    end  
      
    C2 \--\> D\[Post-Processor \<br/\> (Python Logic / Numbering)\]  
      
    C1 \--\> E\[Aggregator\]  
    D \--\> E  
    C3 \--\> E  
      
    E \--\> Output\[Final JSON\]

---

## **2\. データ構造設計 (Pydantic Schema)**

「完璧な再現」のためには、LLMの出力揺れを許容してはならない。OpenAI APIの Structured Outputs (Pydantic) を使用し、データ型を強制する。

### **2.1 実験メソッド (Methods)**

Python

from pydantic import BaseModel, Field  
from typing import List, Optional, Literal

class ExperimentItem(BaseModel):  
    section: str \= Field(..., description="例: 4.1.1")  
    idx: int  
    subidx: Optional\[int\]  
    name: str  
    measurement\_conditions: str  
    experiment\_type: Literal\["測定", "計算", "分析"\]  
    tool: Optional\[str\]

class MethodExtractionResult(BaseModel):  
    experiments: List\[ExperimentItem\]

### **2.2 考察ユニット (Discussion)**

Python

class DiscussionUnit(BaseModel):  
    index: int  
    discussion\_active: str \= Field(..., description="能動態・常体に正規化されたテキスト")  
    reference\_ids: List\[int\] \= Field(default\_factory=list)

class ReferenceItem(BaseModel):  
    id: int  
    title: str

class DiscussionResult(BaseModel):  
    units: List\[DiscussionUnit\]  
    references: List\[ReferenceItem\]

### **2.3 まとめ (Summary)**

Python

class SummaryResult(BaseModel):  
    summary: str \= Field(..., max\_length=340, description="だ・である調、300字程度")

---

## **3\. 実装手順書 (Implementation Guide)**

### **Phase 1: 環境構築とPDF抽出エンジンの選定**

Difyの標準抽出器よりも高速・高精度なライブラリを選定する。

* **推奨**: PyMuPDF (fitz)  
  * 理由: pdfminer.six より圧倒的に高速。  
* **処理**: ヘッダー・フッター（ページ番号など）を、座標情報に基づいて物理的に除外するロジックをここで組み込む（Difyでは難しかった微調整が可能）。

### **Phase 2: Smart Splitter (正規表現ロジック) の実装**

先ほどのPythonコードを強化し、クラス化する。

* **機能**: 全文テキストを受け取り、MethodContext, DiscussionContext, FullContext オブジェクトを返す。  
* **例外処理**: 「実験方法」という見出しが見つからない場合、文書の先頭から2割〜6割を実験方法とみなす等のフォールバックロジックを追加する。

### **Phase 3: 非同期LLMクライアントの実装 (核心)**

Pythonの asyncio を使用し、3つのLLMタスクを\*\*「よーいドン」で同時に走らせる\*\*。これにより、待ち時間は「最も遅いタスク（通常はDiscussion）」の時間のみとなる。直列処理に比べて**3倍以上の高速化**が見込める。

Python

import asyncio  
from openai import AsyncOpenAI

client \= AsyncOpenAI()

async def process\_document(full\_text: str):  
    \# 1\. Split  
    contexts \= smart\_splitter(full\_text)  
      
    \# 2\. Define Tasks (Parallel)  
    \# それぞれの関数内で client.beta.chat.completions.parse を呼ぶ  
    task\_summary \= generate\_summary(contexts.full\_text)  
    task\_methods \= extract\_methods(contexts.method\_text)  
    task\_discussion \= normalize\_discussion(contexts.discussion\_text)  
      
    \# 3\. Execute in Parallel  
    summary, raw\_methods, discussion \= await asyncio.gather(  
        task\_summary,   
        task\_methods,   
        task\_discussion  
    )  
      
    return summary, raw\_methods, discussion

### **Phase 4: 決定論的ポストプロセッサ (Post-Processing Logic)**

Difyのコードノードで行っていた処理を、より堅牢なPython関数として実装する。

* **採番ロジック**: raw\_experiments リストを走査し、table\_counter, fig\_counter をインクリメントしながら tables, figures オブジェクトを生成。  
* **Description生成**: f-stringを使用したテンプレート挿入。  
  * *改善点*: Difyでは難しかった「日本語の助詞の揺らぎ制御（てにをは）」や「条件分岐による微調整」をここで行う。

### **Phase 5: 結合と検証 (Aggregation & Validation)**

各パーツを結合し、最終的なJSONスキーマと照合する。

* もし experiments が空であればエラーフラグを立てる等のバリデーションを行う。

---

## **4\. 盲点とリスク管理（鏡としての指摘）**

あなたがプログラミング実装を行う際、以下の点でつまづく、あるいは「甘く見る」可能性が高いです。

1. **トークン長制限のエラーハンドリング**:  
   * **リスク**: PDFが予想以上に巨大（論文まるごと等）だった場合、コンテキストウィンドウ（128kなど）を超過、あるいは出力制限でJSONが切れる。  
   * **対策**: tiktoken で事前に入力トークン数をカウントし、超過する場合は「Smart Splitter」の段階で重要度の低いセクション（参考文献リストや付録）を物理的に切り捨てるロジックを入れること。  
2. **PDFのレイアウト崩れ**:  
   * **リスク**: 2段組みのPDFなどで、テキスト抽出順序がバラバラになり、文脈が壊れる。  
   * **対策**: PyMuPDF の抽出モード設定を調整するか、レイアウト解析API（Azure Document Intelligenceなど）への切り替えを検討する分岐を用意する。最初は単純な抽出で良いが、精度が出ない場合はここがボトルネックになる。  
3. **LLMのJSON準拠違反**:  
   * **リスク**: 稀にSchemaに従わないJSONを返すことがある。  
   * **対策**: OpenAIの Structured Outputs (response\_format: json\_schema) を**必ず**使うこと。単なる "JSON mode" ではなく、Schema強制モードを使うことで、解析エラーをゼロにできる。

## **5\. 次のアクション**

この設計書に基づき、開発を開始してください。  
最初に作成すべきは Phase 2 の Smart Splitter と Phase 3 の Async Engine のプロトタイプです。ここさえ動けば、あとはプロンプト調整の問題に過ぎません。  
コードの雛形が必要であれば、「asyncioを使った並列処理のボイラープレートを書いて」と指示してください。